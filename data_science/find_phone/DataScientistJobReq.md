# (Remote) Data Scientist - Rackspace Private Cloud

Rackspace is a rapidly growing hosting company based in San Antonio, Texas
that is home to the term "fanatical support" -- providing incredible customer support
and hosting value for those that are making the logical move to hosted computing.
We are growing rapidly due to our past successes (delighted customers), business model 
and excellent customer support, and are looking for highly-motivated, competent individuals 
that can help us get to the next level.

Specifically, the Rackspace Private Cloud team is looking for an awesome Data Scientist 
who has a great blend of raw intelligence, industry and data experience, and the ability to 
work and communicate clearly with people.

## Rackspace Data Scientist

Data Science is an engineering discipline that combines software development with
knowledge of probability, statistics, data modeling, visualization, and machine
learning.  Data Scientists at Rackspace work with massive amounts of recent
and legacy data across several different storage systems including Hive, SQL
Server, and Big Query.  A successful candidate in this role works with team
members, stakeholders, and customers to identify the questions needed to solve
business problems, understand how to leverage data analysis and software to
answer those questions, and can present the answers coherently and concisely to
business customers and stakeholders.

### Knowledge, Skills, Ability

It's important to go into a job understanding what you'll be working on, and what
skills you need to be successful.  We've outlined some requirements below to
help you get a feel for the job and what you'll be doing day-to-day.  At a high
level, we're looking for folks who can jump right into the middle of our data,
sit down with customers, and start understanding how to build models and create
reports in order to help our team make more data-driven management decisions.

#### Required

These are some attributes that we think a successful candidate will need in order
to be effective in the role.  We know people have different strengths and
weaknesses, but you should have some experience with all of these, and be ready
to use them on a daily basis.

  - Strong experience in machine learning techniques (unsupervised, supervised, reinforcement, 
    demonstration, etc.) and optimization algorithms that include statistical analysis techniques 
    such as Grouping, Clustering and Linear Regression.
  - Familiarity with data architecture, specifically data pipelines and data warehouses/lakes.
  - Understanding of SQL and no-SQL databases and the ability to read, write and
    optimize complex queries.
  - Familiarity with big data tools like Spark, Hadoop, Kafka or their cloud equivalents.
  - Proficiency with at least one programming language like Python or R, to a
    level where you are comfortable writing a complete stand-alone application
    to Exploratory Data Analysis (EDA).

#### Additional

In addition to the key skills listed above, here are some other skills that
you'll likely be using on a regular basis.  We don't expect everyone to have all
of these skills, but exceptional candidates will have experience with, or be
excited to learn, most of these:

  - Familiarity with data visualization, including proficiency with at least one
    data visualization framework such as Tableau, Looker, Canvas, Processing or D3.
  - Familiarity with interactive notebooks to communicate your work such as iPython, 
    Jupyter or Google DataLab.
  - Knowledge of business analytics, and comfort working with stakeholders using
    common business terminology.
  - Experience working on software development projects and with common Software Development
    Lifecycle patterns such as Agile/Scrum/Kanban.
  - Familiarity and experience with Natural Language Processing (NLP) and text data mining.
  - Familiarity and experience with deep learning tools and techniques using tools such as 
    TensorFlow, Theano, etc.

### Supervision

We're a helpful and supportive group, and we're not going to leave you without a
clue of where to go or what to do.  That said, we're looking for senior level
individuals who can demonstrate a high degree of autonomy and provide
self-direction.  After all, you'll be the domain expert in your area.

  - Operate with little or no direct Supervision.
  - Work with stakeholders and customers inside of Rackspace to set priorities
    and goals.
  - Self-organize with other team members to deliver customer value.

### Experience and Education

There are a lot of ways to get experience.  Hands on work and education are both
great ways to learn what you need to do for the job.  We're looking for someone who
has a masters or doctorate degree in statistics, physics, mathematics, computer science 
or another technology-related field, as well as 5-7 years of hands-on experience working
with statistical and data analysis.

## Ops Fabric Data Science Focus*

As a member of the Rackspace Private Cloud (RPC) Operational Fabric team, you'll
work with software developers, SREs, and stakeholders to build help us transform
RPC into a data-driven organization.  You'll do this by helping our team
understand the existing data, asking the right questions, gathering the right
information, and building models and self-service reports to help our business
leaders make sound data-driven decisions about how to scale and operate our
organization.

### About Us

- **Team Size**: Currently 8 senior developers/engineers and a technical manager
- **Hours**: We have flexible working hours and aim for a median of 35-40 hours a week
- **Location**: US/UK work from home with offices in US/UK (most states supported)
- **Travel**: About once or twice a year for a conference or team gathering

### Responsibilities

## Additional Info